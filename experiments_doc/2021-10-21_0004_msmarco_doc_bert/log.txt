2021-10-21 00:04:34,956 INFO Running: ['.\\matchmaker\\train.py', '--run-name', 'msmarco_doc_bert', '--config-file', '.\\config\\train\\defaults_bert.yaml', '.\\config\\train\\msmarco_doc.yaml']
2021-10-21 00:04:34,975 INFO Torch seed: 208973249 
2021-10-21 00:04:43,525 INFO Model bert_cat total parameters: 66363649
2021-10-21 00:04:43,525 INFO Network: BERT_Cat(
  (bert_model): DistilBertModel(
    (embeddings): Embeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layer): ModuleList(
        (0): TransformerBlock(
          (attention): MultiHeadSelfAttention(
            (dropout): Dropout(p=0.1, inplace=False)
            (q_lin): Linear(in_features=768, out_features=768, bias=True)
            (k_lin): Linear(in_features=768, out_features=768, bias=True)
            (v_lin): Linear(in_features=768, out_features=768, bias=True)
            (out_lin): Linear(in_features=768, out_features=768, bias=True)
          )
          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (ffn): FFN(
            (dropout): Dropout(p=0.1, inplace=False)
            (lin1): Linear(in_features=768, out_features=3072, bias=True)
            (lin2): Linear(in_features=3072, out_features=768, bias=True)
          )
          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
        (1): TransformerBlock(
          (attention): MultiHeadSelfAttention(
            (dropout): Dropout(p=0.1, inplace=False)
            (q_lin): Linear(in_features=768, out_features=768, bias=True)
            (k_lin): Linear(in_features=768, out_features=768, bias=True)
            (v_lin): Linear(in_features=768, out_features=768, bias=True)
            (out_lin): Linear(in_features=768, out_features=768, bias=True)
          )
          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (ffn): FFN(
            (dropout): Dropout(p=0.1, inplace=False)
            (lin1): Linear(in_features=768, out_features=3072, bias=True)
            (lin2): Linear(in_features=3072, out_features=768, bias=True)
          )
          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
        (2): TransformerBlock(
          (attention): MultiHeadSelfAttention(
            (dropout): Dropout(p=0.1, inplace=False)
            (q_lin): Linear(in_features=768, out_features=768, bias=True)
            (k_lin): Linear(in_features=768, out_features=768, bias=True)
            (v_lin): Linear(in_features=768, out_features=768, bias=True)
            (out_lin): Linear(in_features=768, out_features=768, bias=True)
          )
          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (ffn): FFN(
            (dropout): Dropout(p=0.1, inplace=False)
            (lin1): Linear(in_features=768, out_features=3072, bias=True)
            (lin2): Linear(in_features=3072, out_features=768, bias=True)
          )
          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
        (3): TransformerBlock(
          (attention): MultiHeadSelfAttention(
            (dropout): Dropout(p=0.1, inplace=False)
            (q_lin): Linear(in_features=768, out_features=768, bias=True)
            (k_lin): Linear(in_features=768, out_features=768, bias=True)
            (v_lin): Linear(in_features=768, out_features=768, bias=True)
            (out_lin): Linear(in_features=768, out_features=768, bias=True)
          )
          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (ffn): FFN(
            (dropout): Dropout(p=0.1, inplace=False)
            (lin1): Linear(in_features=768, out_features=3072, bias=True)
            (lin2): Linear(in_features=3072, out_features=768, bias=True)
          )
          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
        (4): TransformerBlock(
          (attention): MultiHeadSelfAttention(
            (dropout): Dropout(p=0.1, inplace=False)
            (q_lin): Linear(in_features=768, out_features=768, bias=True)
            (k_lin): Linear(in_features=768, out_features=768, bias=True)
            (v_lin): Linear(in_features=768, out_features=768, bias=True)
            (out_lin): Linear(in_features=768, out_features=768, bias=True)
          )
          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (ffn): FFN(
            (dropout): Dropout(p=0.1, inplace=False)
            (lin1): Linear(in_features=768, out_features=3072, bias=True)
            (lin2): Linear(in_features=3072, out_features=768, bias=True)
          )
          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
        (5): TransformerBlock(
          (attention): MultiHeadSelfAttention(
            (dropout): Dropout(p=0.1, inplace=False)
            (q_lin): Linear(in_features=768, out_features=768, bias=True)
            (k_lin): Linear(in_features=768, out_features=768, bias=True)
            (v_lin): Linear(in_features=768, out_features=768, bias=True)
            (out_lin): Linear(in_features=768, out_features=768, bias=True)
          )
          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (ffn): FFN(
            (dropout): Dropout(p=0.1, inplace=False)
            (lin1): Linear(in_features=768, out_features=3072, bias=True)
            (lin2): Linear(in_features=3072, out_features=768, bias=True)
          )
          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
      )
    )
  )
  (_classification_layer): Linear(in_features=768, out_features=1, bias=True)
)
2021-10-21 00:04:46,355 INFO [Epoch 0] --- Start training 
2021-10-21 00:17:31,465 INFO [eval_model] --- Start validation from loader
2021-10-21 00:18:26,286 INFO 4000Saved new best weights with: nDCG@10: 0.34590623133917303
2021-10-21 00:18:26,286 INFO 4000-BERT_cat: / 
2021-10-21 00:30:09,325 INFO [eval_model] --- Start validation with cache size:54
2021-10-21 00:30:26,668 INFO 8000-BERT_cat: / 
2021-10-21 00:42:07,698 INFO [eval_model] --- Start validation with cache size:54
2021-10-21 00:42:25,709 INFO 12000Saved new best weights with: nDCG@10: 0.35250754362395215
2021-10-21 00:42:25,709 INFO 12000-BERT_cat: / 
2021-10-21 00:54:02,686 INFO [eval_model] --- Start validation with cache size:54
2021-10-21 00:54:18,877 INFO 16000-BERT_cat: / 
2021-10-21 01:05:27,981 INFO [eval_model] --- Start validation with cache size:54
2021-10-21 01:05:44,710 INFO 20000Saved new best weights with: nDCG@10: 0.37607871497955014
2021-10-21 01:05:44,710 INFO 20000-BERT_cat: / 
2021-10-21 01:13:26,981 INFO [Epoch 1] --- Start training 
2021-10-21 01:25:31,674 INFO [eval_model] --- Start validation with cache size:54
2021-10-21 01:25:48,525 INFO 4000-BERT_cat: / 
2021-10-21 01:37:14,615 INFO [eval_model] --- Start validation with cache size:54
2021-10-21 01:37:31,258 INFO 8000-BERT_cat: / 
2021-10-21 01:48:56,841 INFO [eval_model] --- Start validation with cache size:54
2021-10-21 01:49:14,076 INFO 12000Saved new best weights with: nDCG@10: 0.3905928860060731
2021-10-21 01:49:14,076 INFO 12000-BERT_cat: / 
2021-10-21 02:00:40,165 INFO [eval_model] --- Start validation with cache size:54
2021-10-21 02:00:56,808 INFO 16000-BERT_cat: / 
2021-10-21 02:12:20,227 INFO [eval_model] --- Start validation with cache size:54
2021-10-21 02:12:36,422 INFO 20000-BERT_cat: / 
2021-10-21 02:20:14,562 INFO [Epoch 2] --- Start training 
2021-10-21 02:32:00,652 INFO [eval_model] --- Start validation with cache size:54
2021-10-21 02:32:16,845 INFO 4000-BERT_cat: / 
2021-10-21 08:06:46,170 INFO [eval_model] --- Start validation with cache size:54
2021-10-21 08:07:02,452 INFO 8000-BERT_cat: / 
2021-10-21 08:18:20,812 INFO [eval_model] --- Start validation with cache size:54
2021-10-21 08:18:37,189 INFO 12000-BERT_cat: / 
2021-10-21 08:29:50,940 INFO [eval_model] --- Start validation with cache size:54
2021-10-21 08:30:07,651 INFO 16000-BERT_cat: / 
2021-10-21 08:41:24,549 INFO [eval_model] --- Start validation with cache size:54
2021-10-21 08:41:41,182 INFO 20000-BERT_cat: / 
2021-10-21 08:49:27,090 INFO [Epoch 3] --- Start training 
2021-10-21 09:01:13,858 INFO [eval_model] --- Start validation with cache size:54
2021-10-21 09:01:30,041 INFO 4000-BERT_cat: / 
2021-10-21 09:12:38,707 INFO [eval_model] --- Start validation with cache size:54
2021-10-21 09:12:54,858 INFO 8000-BERT_cat: / 
2021-10-21 09:24:03,117 INFO [eval_model] --- Start validation with cache size:54
2021-10-21 09:24:19,275 INFO 12000-BERT_cat: / 
2021-10-21 09:35:27,542 INFO [eval_model] --- Start validation with cache size:54
2021-10-21 09:35:43,699 INFO 16000-BERT_cat: / 
2021-10-21 09:46:51,776 INFO [eval_model] --- Start validation with cache size:54
2021-10-21 09:47:07,943 INFO 20000-BERT_cat: / 
2021-10-21 09:54:56,423 INFO [eval_model] --- Start validation from loader
